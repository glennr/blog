[{"content":"I recently ran into a simple but frustrating issue with Drata\u0026rsquo;s Agent for Linux. The agent wouldn\u0026rsquo;t start, and the logs showed this error:\nLaunchProcess: failed to execvp: /opt/Drata [FATAL:zygote_host_impl_linux.cc(201)] Check failed: . : Invalid argument (22) After checking ps to confirm the process wasn\u0026rsquo;t running and looking through system logs with dmesg and tail -f /var/log/*, I took a closer look at my autostart file:\nExec=/opt/\u0026#34;Drata Agent\u0026#34;/drata-agent The issue? A space in the directory name. While the command worked in the terminal with quotes, the autostart system couldn\u0026rsquo;t handle it properly and was only executing /opt/Drata.\nThe fix was straightforward:\nsudo mv \u0026#34;Drata Agent\u0026#34; DrataAgent And updating the autostart config:\nExec=/opt/DrataAgent/drata-agent After this change, the agent started without issues. A simple space in a directory name was the culprit all along.\n","date":"14 March 2025","permalink":"/posts/2025/03/14/a-space-broke-the-drata-agent/","section":"Posts","summary":"","title":"A Space Broke the Drata Agent"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/tags/drata/","section":"Tags","summary":"","title":"Drata"},{"content":" Elixir, Full-stack, DevSecOps, Gluer of Things. ","date":null,"permalink":"/","section":"Glenn Roberts' blog","summary":"","title":"Glenn Roberts' blog"},{"content":"","date":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"Linux"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/categories/troubleshooting/","section":"Categories","summary":"","title":"Troubleshooting"},{"content":"","date":null,"permalink":"/categories/development/","section":"Categories","summary":"","title":"Development"},{"content":"","date":null,"permalink":"/tags/mise/","section":"Tags","summary":"","title":"Mise"},{"content":"","date":null,"permalink":"/tags/neovim/","section":"Tags","summary":"","title":"Neovim"},{"content":"","date":null,"permalink":"/tags/troubleshooting/","section":"Tags","summary":"","title":"Troubleshooting"},{"content":"Imagine this: you\u0026rsquo;re happily typing away in Neovim, living your best dev life, and suddenly you see an error message like this:\nmise ERROR No version is set for shim: node Set a global default version with one of the following: mise use -g node@latest And you think: \u0026ldquo;But hang on, I do have node = \u0026quot;latest\u0026quot; in my global Mise config (~/.config/mise/config.toml)—did Mise not even read it?\u0026rdquo;\nWell, yes. And, bizarrely, also no. This is the story of how I discovered Mise was effectively giving my global config the silent treatment—while insisting it was \u0026ldquo;tracked.\u0026rdquo; Below is the journey, the misdirections that could lead you astray, and the eventual fix that saved my Neovim setup from imploding.\n1. The Symptom: Shell Fine, Neovim Complaining #Neovim\u0026rsquo;s Perspective # LSP and plugins throw \u0026ldquo;No version is set for shim: node.\u0026rdquo; Running :!mise doctor inside Neovim might still show shims_on_path: yes, implying it does find the shims. However, any configured tools (like Node or Python versions) aren\u0026rsquo;t actually recognised. If you run mise doctor in Neovim and see: ignored_config_files: ~/.config/mise/config.toml …that\u0026rsquo;s the bright, flashing sign that your global config is effectively in the naughty corner. Shell\u0026rsquo;s Perspective # Initially, your shell appears fine. Possibly from earlier usage or leftover state, you could run Node without hassle. But if you check mise doctor in the shell and see the same \u0026ldquo;ignored_config_files\u0026rdquo; line, then yes—Mise is ignoring ~/.config/mise/config.toml there, too. The difference is that your shell had enough leftover \u0026ldquo;environment sauce\u0026rdquo; to carry on, while Neovim was left out in the cold. Basically, the shell was \u0026ldquo;putting on a brave face,\u0026rdquo; but Neovim was being more candid: no global config, no party.\n2. The Red Herrings #It\u0026rsquo;s easy to go down a rabbit hole here. These were my (infuriating) potential culprits along the way.\nRed Herring #1: Missing eval \u0026quot;$(mise init -)\u0026quot; in Your Shell RC #Mise generally wants you to eval \u0026quot;$(mise init -)\u0026quot; in your ~/.bashrc or ~/.zshrc. If you haven\u0026rsquo;t done that, heartbreak can follow. But if your shell and Neovim shell commands both report \u0026ldquo;activated: yes\u0026rdquo; in mise doctor, then you know this isn\u0026rsquo;t the problem. Next suspect, please.\nRed Herring #2: Neovim Missing Shims in PATH #It\u0026rsquo;s common to forget to prepend ~/.local/share/mise/shims to Neovim\u0026rsquo;s PATH. (The Mise docs mention it, if you RTFM) If that\u0026rsquo;s missing, you might indeed see \u0026ldquo;No version is set.\u0026rdquo; In this situation, though, I\u0026rsquo;d already done:\nlocal mise_shim_path = vim.fn.expand(\u0026#34;~/.local/share/mise/shims\u0026#34;) vim.env.PATH = mise_shim_path .. \u0026#34;:\u0026#34; .. vim.env.PATH So the shims were recognised, yet the dreaded \u0026ldquo;No version is set\u0026rdquo; still appeared. Therefore, not the culprit.\nRed Herring #3: Invalid config.toml or Stray BOM #Sometimes a sneaky \u0026ldquo;invisible\u0026rdquo; character or a bung [tools] block can cause issues. But I triple-checked, and it was squeaky clean—no stray BOM, no dodgy syntax. Another suspect ruled out.\n3. The Real Culprit: Duplicate Entries in ignored-configs/ and tracked-configs/ #Deep inside Mise\u0026rsquo;s labyrinthine innards, you\u0026rsquo;ll find two directories:\n~/.local/state/mise/tracked-configs/ ~/.local/state/mise/ignored-configs/ They\u0026rsquo;re basically two lists of symlinks: one for config files Mise actively loads, and one for config files it\u0026rsquo;s ignoring. The kicker: if your ~/.config/mise/config.toml somehow appears in both with the same hash, you get Schrödinger\u0026rsquo;s config—both \u0026ldquo;tracked\u0026rdquo; and \u0026ldquo;ignored,\u0026rdquo; which effectively means ignored.\nHere\u0026rsquo;s what I found when I looked at my own setup:\n❯ ls -al ~/.local/state/mise/ignored-configs/ Permissions Size User Date Modified Name lrwxrwxrwx - g 27 Nov 2024 mise-config.toml-506ade9caf4d46ff -\u0026gt; /home/g/.config/mise/config.toml ❯ ls -al ~/.local/state/mise/tracked-configs/ Permissions Size User Date Modified Name lrwxrwxrwx - g 11 Mar 15:16 49bc95cf95659576 -\u0026gt; /home/g/mise-test/.mise.toml lrwxrwxrwx - g 10 Oct 2024 506ade9caf4d46ff -\u0026gt; /home/g/.config/mise/config.toml Notice the exact same hash identifier (506ade9caf4d46ff) appearing in both directories? That\u0026rsquo;s the smoking gun. My config.toml contained simple version settings:\nBut…why? #You might have told Mise to \u0026ldquo;ignore\u0026rdquo; that config at some point (maybe after a prompt to trust or not trust the config?), and then later on you or Mise tried to track it again. Now Mise is confused, sees it in both lists, and the \u0026ldquo;ignore\u0026rdquo; overrides your \u0026ldquo;track.\u0026rdquo; Classic.\n4. Fixing It # Remove the Symlink in ignored-configs/. cd ~/.local/state/mise/ignored-configs ls -l # find something referencing ~/.config/mise/config.toml rm mise-config.toml-\u0026lt;some-hash\u0026gt; Check tracked-configs/. Make sure your config is still there. If it\u0026rsquo;s missing, Mise may recreate it once you run mise doctor or another command.\n(Optional) Wipe All Mise State. If you want a truly clean slate:\nrm -rf ~/.local/state/mise Then re-run mise doctor or mise use -g ... so Mise can rebuild everything.\nAfter that, if you run mise doctor, you should see something like:\nshims_on_path: yes config_files: ~/.config/mise/config.toml ignored_config_files: (none) And—finally—Neovim\u0026rsquo;s LSP or plugins will finally respect your global config\u0026rsquo;s versions.\nConclusion #If you\u0026rsquo;re getting \u0026ldquo;No version is set for shim: node\u0026rdquo; in Neovim (but not obviously in your shell), don\u0026rsquo;t be misled by typical PATH or shell init suspects. Check ~/.local/state/mise/ignored-configs/ to see if your global mise config is blacklisted. With that fixed, Neovim\u0026rsquo;s LSP or plugins will properly recognize the correct binaries.\nQuick Recap: # Look for your ~/.config/mise/config.toml under ignored-configs/. Remove it if it\u0026rsquo;s there. Confirm you get shims_on_path: yes for both shell and Neovim. Celebrate having consistent tool versions everywhere! Hopefully that saves you the same confusion I faced. Happy debugging!\n","date":"11 March 2025","permalink":"/posts/2025/03/11/when-mise-ignores-your-global-config-a-tale-of-red-herrings-and-stale-state/","section":"Posts","summary":"","title":"When Mise Ignores Your Global Config: A Tale of Red Herrings and Stale State"},{"content":"","date":null,"permalink":"/tags/aws/","section":"Tags","summary":"","title":"AWS"},{"content":"","date":null,"permalink":"/categories/devops/","section":"Categories","summary":"","title":"DevOps"},{"content":"","date":null,"permalink":"/tags/iac/","section":"Tags","summary":"","title":"IaC"},{"content":"Need to delegate access to your AWS billing dashboard to folks in your finance team? Here\u0026rsquo;s how you can define the necessary policies using Pulumi for your Infrastructure As Code (IaC).\nFirst, create an IAM Group:\nconst group = new aws.iam.Group(\u0026#34;finance\u0026#34;, { path }); Next, define the policy:\nfunction billingFullPolicy() { const policyDefn: aws.iam.PolicyDocument = { Version: \u0026#34;2012-10-17\u0026#34;, Statement: [ { Action: [ \u0026#34;aws-portal:*Billing\u0026#34;, \u0026#34;aws-portal:*PaymentMethods\u0026#34;, \u0026#34;aws-portal:ViewUsage\u0026#34;, \u0026#34;billing:ListBillingViews\u0026#34;, \u0026#34;ce:*\u0026#34;, \u0026#34;cur:*\u0026#34;, \u0026#34;pricing:*\u0026#34;, \u0026#34;purchase-orders:*\u0026#34;, \u0026#34;support:AddAttachmentsToSet\u0026#34;, \u0026#34;support:CreateCase\u0026#34;, \u0026#34;sustainability:GetCarbonFootprintSummary\u0026#34;, \u0026#34;tax:*\u0026#34;, ], Resource: \u0026#34;*\u0026#34;, Effect: \u0026#34;Allow\u0026#34;, Sid: \u0026#34;FullBillingAndReporting\u0026#34;, }, ], }; return new aws.iam.Policy(\u0026#34;GrantFullAccessToBilling\u0026#34;, { description: `Allow manage billing`, policy: policyDefn, }); } Note this is quite a permissive policy, and you might want to reserve it only for financial \u0026lsquo;administrators\u0026rsquo;.\nA Read-only billing policy might be better suited for reporting users, which might exclude creating Cost and Usage reports (cur:*) or accessing account settings:\nfunction billingReadOnlyPolicy() { const policyDefn: aws.iam.PolicyDocument = { Version: \u0026#39;2012-10-17\u0026#39;, Statement: [ { Action: [ \u0026#39;aws-portal:ViewBilling\u0026#39;, \u0026#39;aws-portal:ViewUsage\u0026#39;, \u0026#39;billing:ListBillingViews\u0026#39;, \u0026#39;ce:GetCostAndUsage\u0026#39; \u0026#39;cur:DescribeReportDefinitions\u0026#39;, \u0026#39;pricing:*\u0026#39;, \u0026#39;purchase-orders:View*\u0026#39;, \u0026#39;support:AddAttachmentsToSet\u0026#39;, \u0026#39;support:CreateCase\u0026#39;, \u0026#39;sustainability:GetCarbonFootprintSummary\u0026#39;, \u0026#39;tax:Get*\u0026#39;, ], Resource: \u0026#39;*\u0026#39;, Effect: \u0026#39;Allow\u0026#39;, Sid: \u0026#39;FullBillingAndReporting\u0026#39;, }, { Effect: \u0026#39;Deny\u0026#39;, Action: \u0026#39;aws-portal:*Account\u0026#39;, Resource: \u0026#39;*\u0026#39;, Sid: \u0026#39;\u0026#39; } ], } return new aws.iam.Policy(\u0026#39;GrantReadAccessToBilling\u0026#39;, { description: \u0026#39;Allow read-only access to billing\u0026#39;, policy: policyDefn, }) } Attach the desired policy to the Finance group you created.\nnew aws.iam.GroupPolicyAttachment(\u0026#34;attach-full-billing\u0026#34;, { group: group.name, policyArn: billingFullPolicy().arn, }); Now all the IAM users you add to this group will be able to access the these billing permissions.\nAWS provides plenty of billing examples, and it\u0026rsquo;s a simple matter of copying the JSON policy into your Pulumi definitions, using the typescript template above. As an added bonus, if you\u0026rsquo;re using Typescript, your editor should autoformat the JSON definition for you.\nIaC gives you a number of benefits. You have an excellent audit trail, since all policy versions are in a git repository. Your infrastructure is expressed using a familiar, Turing-complete programming language. You manage and deploy code using the same toolchains your DevOps team uses daily.\nWhen you add IaC to your CI/CD pipeline, your cloud infrastructure stays in sync with your definitions. With a tool like Pulumi you also get a web-based dashboard a history of all updates applied to your cloud infrastructure.\n(While it sounds like I\u0026rsquo;m affiliated with Pulumi, I\u0026rsquo;m not. I am however happy user of their product!)\n","date":"16 November 2022","permalink":"/posts/2022/11/16/let-your-finance-team-track-aws-spend/","section":"Posts","summary":"","title":"Let Your Finance Team Track AWS Spend"},{"content":"","date":null,"permalink":"/tags/pulumi/","section":"Tags","summary":"","title":"Pulumi"},{"content":"","date":null,"permalink":"/tags/devsecops/","section":"Tags","summary":"","title":"DevSecOps"},{"content":"","date":null,"permalink":"/tags/nist/","section":"Tags","summary":"","title":"NIST"},{"content":"NIST 800-63, section 5 describes the following guidelines for passwords (aka \u0026ldquo;memorized secrets\u0026rdquo;):\nat least 64 characters, all ASCII (including spaces and Unicode characters) no reusing passwords No password expiration period. No password hints. disallow passwords from data breaches, dictionary or context-specific words, or repetitive or sequential characters Warning! This list excludes several important recommendations like expiry, rate limiting and MFA. NIST now de-emphasizes forcing the use of certain characters (for example uppercase letters, numbers, or special chars like ! @ # $ %) and forcing periodic password rotation. This runs contrary to many password schemes you\u0026rsquo;ve probably encountered in the wild.\nAWS is no exception. Account Password Policies lags these recommendations. There are many (optional) parameters, like requireSymbols, that you can ignore when implementing password schemes for your infrastructure in-line with the latest NIST recommendations.\nHere\u0026rsquo;s what that might look like if you\u0026rsquo;re using Pulumi to manage your infrastructure definitions:\nnew aws.iam.AccountPasswordPolicy(\u0026#34;nist22-ish\u0026#34;, { allowUsersToChangePassword: true, minimumPasswordLength: 64, requireLowercaseCharacters: false, requireNumbers: false, requireSymbols: false, requireUppercaseCharacters: false, passwordReusePrevention: 24, }); The 64 character minimum might seem onerous, but is less of a problem if you use a password manager, or can recite prose from memory /s.\nThis is just a starting point however. As mentioned above, in the same section NIST additionally recommends using second (2FA) or multi-factor (MFA) devices. Start here with some AWS policy definitions you could use to enforce MFA.\n","date":"16 November 2022","permalink":"/posts/2022/11/16/nist-and-aws-password-policies/","section":"Posts","summary":"","title":"NIST and AWS Password Policies"},{"content":"","date":null,"permalink":"/categories/security/","section":"Categories","summary":"","title":"Security"},{"content":"","date":null,"permalink":"/categories/blogging/","section":"Categories","summary":"","title":"Blogging"},{"content":"","date":null,"permalink":"/tags/lunarvim/","section":"Tags","summary":"","title":"LunarVim"},{"content":"Vale.sh is a great tool for enforcing a writing style in your documents.\nMy vale.sh setup follows the one described in Writing like a pro with vale \u0026amp; Neovim, (albeit with my preferred LunarVim).\nOnce you\u0026rsquo;ve got Vale up and running, both it and Neovim spell checking will complain about the same things. Technical terms often appear as false positives, so the zg shortcut is handy. (zg adds the word under the cursor as a good word to your spellfile.) However Vale.sh still complains about the spelling you just whitelisted:\n Did you really mean \u0026#39;blargh\u0026#39;? vale (Vale.Spelling) [17, 139] A neat workaround is to link Vale Vocabularies accept.txt to your vim spellfile.\nFirst, set up a Vale Vocab folder\nmkdir -p styles/Vocab/Blog/ And configure Vale to use it\ndiff --git a/.vale.ini b/.vale.ini index 636f9f3..db22387 100644 --- a/.vale.ini +++ b/.vale.ini @@ -4,6 +4,8 @@ MinAlertLevel = suggestion Packages = Microsoft, proselint, Hugo +Vocab = Blog + [*] BasedOnStyles = Vale, Microsoft, proselint Then symlink the Vale accept.txt, for example\n% ln -s ~/.config/lvim/spell/en.utf-8.add styles/Vocab/Blog/accept.txt % ll styles/Vocab/Blog/accept.txt lrwxrwxrwx 1 g g 39 Nov 12 17:51 styles/Vocab/Blog/accept.txt -\u0026gt; /home/g/.config/lvim/spell/en.utf-8.add Now if you mark a word as \u0026lsquo;good\u0026rsquo; in Neovim, Vale will accept it too.\n","date":"13 November 2022","permalink":"/posts/2022/11/13/vale.sh-vim-spellcheck/","section":"Posts","summary":"","title":"Vale.sh Vim Spellcheck"},{"content":"","date":null,"permalink":"/tags/vim/","section":"Tags","summary":"","title":"Vim"},{"content":"","date":null,"permalink":"/tags/k6/","section":"Tags","summary":"","title":"K6"},{"content":"Soak tests with k6 might generate this error:\nERRO[0543] GoError: dial tcp 1.2.3.4:443: socket: too many open files running at go.k6.io/k6/js/modules/k6/ws.(*WS).Connect-fm (native) Indicating a hard limit imposed by the Linux kernel, as the k6 process was trying to establish a lot of simultaneous connections.\nThis error can relate to personal file descriptor limits:\n% ulimit -n 1024 The fix was simple:\n% ulimit -n 10000 And to verify:\n% ulimit -n 10000 ","date":"26 October 2022","permalink":"/posts/2022/10/26/k6-soak-tests-too-many-open-files/","section":"Posts","summary":"","title":"K6 Soak Tests: Too Many Open Files"},{"content":"","date":null,"permalink":"/tags/load-testing/","section":"Tags","summary":"","title":"Load-Testing"},{"content":"","date":null,"permalink":"/tags/elixir/","section":"Tags","summary":"","title":"Elixir"},{"content":"Elixir and Phoenix tout high performance with low hardware requirements, and microsecond (μs) response times. Of course Elixir and Phoenix are only one part of your (production) stack, and thus tell only part of the whole story.\nHow well does your Phoenix LiveView app, and infrastructure, perform under stress?\nHow do you baseline performance, and how do you measure the impact of changes on that performance?\nGiven LiveView relies on websocket communication, how do you test that? How memory hungry are your views?\nI recently had to answer these questions for Bramble which is an app built with Phoenix LiveView. I needed something to simulate HTTP and websocket traffic with spikey and sustained workloads.\nEnter k6 #In the past I might have reached for good old Apache JMeter. The new shiny appears to be k6, an open-source load testing tool written by the folks over at Grafana Labs.\nMy initial impression was good. You write your tests in JavaScript, using a simple API:\nimport http from \u0026#34;k6/http\u0026#34;; import { sleep } from \u0026#34;k6\u0026#34;; export default function () { http.get(\u0026#34;https://test.k6.io\u0026#34;); sleep(1); } k6 ships as a Go binary, optimized for minimal resource consumption. To run a load test, your invoke k6 from the command line:\nk6 run --vus 10 --duration 30s script.js This simulates 10 Virtual Users (VUs) over a sustained period of 30 seconds.\nYou\u0026rsquo;ll notice k6 is fast. It doesn\u0026rsquo;t run those tests in a browser or in a NodeJS runtime, but using its own interpreter. This efficiency is important in a load testing tool, as it means you don\u0026rsquo;t need to rent half of AWS to saturate your application endpoints.\nOne added benefit, in the context of testing LiveView, is you don\u0026rsquo;t have to install any extra plugins as websockets are already supported in k6.\nTest setup #Here\u0026rsquo;s a worked example of how to get k6 up and running, and how to test a LiveView app.\nThe test setup will be simple - we\u0026rsquo;ll run both a LiveView app, and k6, locally. We\u0026rsquo;ll write a k6 test script to exercise Chris McCord\u0026rsquo;s LiveBeats project, described as a \u0026ldquo;Social Music App With Phoenix LiveView\u0026rdquo;.\nFor a production setup, you\u0026rsquo;ll likely run the tests against a staging or pre-production system instead. Also observe that k6 running locally on a single machine will probably not be good enough for production-like tests. For this use-case, k6 also supports a distributed load test (Kubernetes) or their commercial k6 Cloud.\nInstall k6 #First, install k6 per [their instructions](https://k6.io/docs/getting-started/installation/. ASDF users can try https://github.com/grimoh/asdf-k6\nSet up a LiveView project #Set up your LiveBeats project per the README\n(The setup is a little funky as you need to create a GitHub OAuth app for your project, but it only takes 2 minutes).\nOpen up LiveBeats on localhost, and sign in.\n(Optionally create some sample data by uploading a few mp3 files you have lying around on your hard drive. You still have some right? Right?)\nLiveBeats has two main URLs we\u0026rsquo;re interested in for this load test:\nThe \u0026lsquo;My Profile\u0026rsquo; for example /YOUR_GITHUB_USERNAME. The Settings page: /profile/settings A k6 test script #Let\u0026rsquo;s start our k6 test script, and make it hit just the Settings page first.\nimport http from \u0026#34;k6/http\u0026#34;; import { sleep, check } from \u0026#34;k6\u0026#34;; const cookie = __ENV.LIVEBEATS_COOKIE; export default function () { let res = http.get(\u0026#34;http://localhost:4000/profile/settings\u0026#34;, { // dont follow authentication failure redirects redirects: 0, cookies: { _live_beats_key_v1: cookie, }, }); check(res, { \u0026#34;status 200\u0026#34;: (r) =\u0026gt; r.status === 200, \u0026#34;contains header\u0026#34;: (r) =\u0026gt; r.body.includes(\u0026#34;Profile Settings\u0026#34;), }); sleep(1); } Source code on GitHub\nFor simplicity, this script skips GitHub OAuth sign in. Instead it expects a valid cookie exposed as an environment variable.\nTo do this grab the _live_beats_key_v1 cookie from your browser, and export it in the same session you\u0026rsquo;ll run k6.\n% export LIVEBEATS_COOKIE=YOUR_COOKIE To run this script, use the k6 binary you installed:\n% k6 run test/k6/load-test.js /\\ |‾‾| /‾‾/ /‾‾/ /\\ / \\ | |/ / / / / \\/ \\ | ( / ‾‾\\ / \\ | |\\ \\ | (‾) | / __________ \\ |__| \\__\\ \\_____/ .io execution: local script: test/k6/load-test.js output: - scenarios: (100.00%) 1 scenario, 1 max VUs, 10m30s max duration (incl. graceful stop): * default: 1 iterations for each of 1 VUs (maxDuration: 10m0s, gracefulStop: 30s) running (00m01.1s), 0/1 VUs, 1 complete and 0 interrupted iterations default ✓ [======================================] 1 VUs 00m01.1s/10m0s 1/1 iters, 1 per VU ✓ status 200 ✓ contains header checks…………………….: 100.00% ✓ 2 ✗ 0 data_received………………: 39 kB 37 kB/s data_sent………………….: 317 B 297 B/s http_req_blocked……………: avg=301.69µs min=301.69µs med=301.69µs max=301.69µs p(90)=301.69µs p(95)=301.69µs http_req_connecting…………: avg=133.67µs min=133.67µs med=133.67µs max=133.67µs p(90)=133.67µs p(95)=133.67µs http_req_duration…………..: avg=63.55ms min=63.55ms med=63.55ms max=63.55ms p(90)=63.55ms p(95)=63.55ms { expected_response:true }…: avg=63.55ms min=63.55ms med=63.55ms max=63.55ms p(90)=63.55ms p(95)=63.55ms http_req_failed…………….: 0.00% ✓ 0 ✗ 1 http_req_receiving………….: avg=208.26µs min=208.26µs med=208.26µs max=208.26µs p(90)=208.26µs p(95)=208.26µs http_req_sending……………: avg=64.63µs min=64.63µs med=64.63µs max=64.63µs p(90)=64.63µs p(95)=64.63µs http_req_tls_handshaking…….: avg=0s min=0s med=0s max=0s p(90)=0s p(95)=0s http_req_waiting……………: avg=63.28ms min=63.28ms med=63.28ms max=63.28ms p(90)=63.28ms p(95)=63.28ms http_reqs………………….: 1 0.938097/s iteration_duration………….: avg=1.06s min=1.06s med=1.06s max=1.06s p(90)=1.06s p(95)=1.06s iterations…………………: 1 0.938097/s vus……………………….: 1 min=1 max=1 vus_max……………………: 1 min=1 max=1 Boom, you can see both checks worked, and various performance statistics for the run. Our p90 HTTP request duration is 63.55ms.\nBaby\u0026rsquo;s first melted CPU #Now let\u0026rsquo;s add the My Profile page endpoint to the script.\nimport http from \u0026#34;k6/http\u0026#34;; import { sleep, check } from \u0026#34;k6\u0026#34;; const cookie = __ENV.LIVEBEATS_COOKIE; export default function () { const options = { redirects: 0, cookies: { _live_beats_key_v1: cookie, }, }; let res = http.get(\u0026#34;http://localhost:4000/profile/settings\u0026#34;, options); check(res, { \u0026#34;status 200\u0026#34;: (r) =\u0026gt; r.status === 200, \u0026#34;contains header\u0026#34;: (r) =\u0026gt; r.body.includes(\u0026#34;Profile Settings\u0026#34;), }); sleep(1); res = http.get(\u0026#34;http://localhost:4000/glennr\u0026#34;, options); check(res, { \u0026#34;songs status 200\u0026#34;: (r) =\u0026gt; r.status === 200, \u0026#34;contains table\u0026#34;: (r) =\u0026gt; r.body.includes(\u0026#34;Artist\u0026#34;), }); sleep(1); } Full diff\nNote this is test doesn\u0026rsquo;t describe a realistic user journey. A sleep time of only 1 second between requests is quite short.\nNext, run this updated k6 script with a twist: dial up the VUs + test duration. This increases both the overall the script iterations, and the load on the app.\n% k6 run test/k6/load-test.js --vus 100 --duration=10s … running (12.0s), 000/100 VUs, 500 complete and 0 interrupted iterations default ✓ [======================================] 100 VUs 10s ✓ status 200 ✓ contains header ✓ songs status 200 ✓ contains table checks…………………….: 100.00% ✓ 2000 ✗ 0 data_received………………: 62 MB 5.2 MB/s data_sent………………….: 312 kB 26 kB/s http_req_blocked……………: avg=92.64µs min=1.56µs med=4.05µs max=3.53ms p(90)=31.17µs p(95)=346.09µs http_req_connecting…………: avg=34.23µs min=0s med=0s max=2.7ms p(90)=5.74µs p(95)=157.69µs http_req_duration…………..: avg=166.02ms min=55.06ms med=158.57ms max=435.99ms p(90)=274.61ms p(95)=323.83ms { expected_response:true }…: avg=166.02ms min=55.06ms med=158.57ms max=435.99ms p(90)=274.61ms p(95)=323.83ms http_req_failed…………….: 0.00% ✓ 0 ✗ 1000 http_req_receiving………….: avg=155.92µs min=37.41µs med=108.94µs max=2.39ms p(90)=240.32µs p(95)=327.97µs http_req_sending……………: avg=32.7µs min=6.24µs med=17.27µs max=2.71ms p(90)=36.1µs p(95)=100.31µs http_req_tls_handshaking…….: avg=0s min=0s med=0s max=0s p(90)=0s p(95)=0s http_req_waiting……………: avg=165.84ms min=54.96ms med=158.41ms max=435.45ms p(90)=274.34ms p(95)=323.64ms http_reqs………………….: 1000 83.414907/s iteration_duration………….: avg=2.33s min=2.14s med=2.31s max=2.58s p(90)=2.46s p(95)=2.53s iterations…………………: 500 41.707454/s vus……………………….: 1 min=1 max=100 vus_max……………………: 100 min=100 max=100 With the increased Our p90 HTTP request duration has increased to 274ms, and we processed 83 HTTP requests per second.\nTry increasing your VU count and observe what happens. I hit my open file descriptor limit at about 1000 VUs. This crashed the phx.server process, and causing all k6 checks to fail. (The BEAM was still running, of course…)\n% k6 run test/k6/load-test.js --vus 1000 --duration=10s Websockets and LiveView #A common LiveView optimization for heavy pages is to defer certain costly operations until the view upgrades to a stateful connection.\ndef mount(params, _session, socket) do %{current_user: current_user} = socket.assigns if connected?(socket) do \u0026lt;do costly things\u0026gt; … As such, any load test that hits these LiveView endpoints purely over HTTP is a lie. To exercise these code paths in a load test, you have to simulate this life cycle by connecting from the client (k6) back to the server over websockets.\nAs mentioned, k6 supports websockets out of the box. (Note: At time of writing the xk6-websockets extension may replace this API.) Lets add some extra checks to the k6 script to exercise LiveView websockets\nimport http from \u0026#34;k6/http\u0026#34;; import { sleep, check, fail } from \u0026#34;k6\u0026#34;; import ws from \u0026#34;k6/ws\u0026#34;; const cookie = __ENV.LIVEBEATS_COOKIE; export default function () { const host = \u0026#34;localhost:4000\u0026#34;; const origin = `http://${host}`; const wsProtocol = \u0026#34;ws\u0026#34;; const options = { redirects: 0, cookies: { _live_beats_key_v1: cookie, }, }; let url = `http://${host}/profile/settings`; let res = http.get(url, options); check(res, { \u0026#34;status 200\u0026#34;: (r) =\u0026gt; r.status === 200, \u0026#34;contains header\u0026#34;: (r) =\u0026gt; r.body.includes(\u0026#34;Profile Settings\u0026#34;), }); checkLiveViewUpgrade(host, origin, wsProtocol, cookie, res, url); sleep(1); url = `http://${host}/glennr`; res = http.get(url, options); check(res, { \u0026#34;songs status 200\u0026#34;: (r) =\u0026gt; r.status === 200, \u0026#34;contains table\u0026#34;: (r) =\u0026gt; r.body.includes(\u0026#34;Artist\u0026#34;), }); checkLiveViewUpgrade(host, origin, wsProtocol, cookie, res, url); sleep(1); } Where checkLiveViewUpgrade looks like this:\n// Connects the websocket to ensure the LV is upgraded. // // - parse the response HTML to find the LiveView websocket connection information (csrf token, topic etc) // - build a `phx_join` message payload // - issue a ws.connect() // - including several callback handlers // - when a socket message was received, we assume the view was upgraded, and the websocket is closed. function checkLiveViewUpgrade( host, testHost, wsProto, cookie, response, url, opts = {} ) { const debug = opts.debug || false; // The response html contains the LV websocket connection details const props = grabLVProps(response); const wsCsrfToken = props.wsCsrfToken; const phxSession = props.phxSession; const phxStatic = props.phxStatic; const topic = `lv:${props.phxId}`; const ws_url = `${wsProto}://${host}/live/websocket?vsn=2.0.0\u0026amp;_csrf_token=${wsCsrfToken}`; if (debug) console.log(`connecting ${ws_url}`); // LV handshake message const joinMsg = JSON.stringify( encodeMsg(null, 0, topic, \u0026#34;phx_join\u0026#34;, { url: url, params: { _csrf_token: wsCsrfToken, _mounts: 0, }, session: phxSession, static: phxStatic, }) ); var response = ws.connect( ws_url, { headers: { Cookie: `_live_beats_key_v1=${cookie}`, Origin: testHost, }, }, function (socket) { socket.on(\u0026#34;open\u0026#34;, () =\u0026gt; { socket.send(joinMsg); if (debug) console.log(`websocket open: phx_join topic: ${topic}`); }), socket.on(\u0026#34;message\u0026#34;, (message) =\u0026gt; { checkMessage(message, `\u0026#34;status\u0026#34;:\u0026#34;ok\u0026#34;`); socket.close(); }); socket.on(\u0026#34;error\u0026#34;, handleWsError); socket.on(\u0026#34;close\u0026#34;, () =\u0026gt; { // should we issue a phx_leave here? if (debug) console.log(\u0026#34;websocket disconnected\u0026#34;); }); socket.setTimeout(() =\u0026gt; { console.log(\u0026#34;2 seconds passed, closing the socket\u0026#34;); socket.close(); fail(\u0026#34;websocket closed\u0026#34;); }, 2000); } ); checkStatus(response, 101); } Helper functions omitted for brevity, but the source code is here\nNote: checkLiveViewUpgrade only tests the websocket connects - it doesn\u0026rsquo;t test the contents of the websocket message (like if the phx_reply rendered some expected HTML.)\nSocket to me #Lets re-run, using the same test parameters as before (100 VUs over 10 seconds)\n% k6 run test/k6/load-test.js --vus 100 --duration=10s /\\ |‾‾| /‾‾/ /‾‾/ /\\ / \\ | |/ / / / / \\/ \\ | ( / ‾‾\\ / \\ | |\\ \\ | (‾) | / __________ \\ |__| \\__\\ \\_____/ .io execution: local script: test/k6/load-test.js output: - scenarios: (100.00%) 1 scenario, 100 max VUs, 40s max duration (incl. graceful stop): * default: 100 looping VUs for 10s (gracefulStop: 30s) running (12.0s), 000/100 VUs, 400 complete and 0 interrupted iterations default ✓ [======================================] 100 VUs 10s ✓ status 200 ✓ contains header ✓ found WS token ✓ found phx-session ✓ found phx-static ✓ ws msg OK ✓ status OK ✓ songs status 200 ✓ contains table checks…………………….: 100.00% ✓ 5600 ✗ 0 data_received………………: 90 MB 7.5 MB/s data_sent………………….: 1.4 MB 113 kB/s http_req_blocked……………: avg=53.16µs min=1.85µs med=4µs max=2.7ms p(90)=144.83µs p(95)=303.66µs http_req_connecting…………: avg=27.56µs min=0s med=0s max=731.28µs p(90)=98.06µs p(95)=196.82µs http_req_duration…………..: avg=246.2ms min=48.1ms med=183.9ms max=538.6ms p(90)=510.16ms p(95)=526.17ms { expected_response:true }…: avg=246.2ms min=48.1ms med=183.9ms max=538.6ms p(90)=510.16ms p(95)=526.17ms http_req_failed…………….: 0.00% ✓ 0 ✗ 800 http_req_receiving………….: avg=648.09µs min=45.68µs med=111.45µs max=15.77ms p(90)=731.57µs p(95)=4.37ms http_req_sending……………: avg=50.46µs min=7.45µs med=16.99µs max=890.78µs p(90)=65.12µs p(95)=268.68µs http_req_tls_handshaking…….: avg=0s min=0s med=0s max=0s p(90)=0s p(95)=0s http_req_waiting……………: avg=245.5ms min=47.96ms med=183.79ms max=525.87ms p(90)=508.92ms p(95)=523.4ms http_reqs………………….: 800 66.634307/s iteration_duration………….: avg=2.88s min=2.31s .config/lvim/spell/en.utf-8.add med=2.78s max=3.6s p(90)=3.5s p(95)=3.54s iterations…………………: 400 33.317153/s vus……………………….: 13 min=13 max=100 vus_max……………………: 100 min=100 max=100 ws_connecting………………: avg=126.45ms min=39.85ms med=103.19ms max=359.7ms p(90)=232.6ms p(95)=305.48ms ws_msgs_received……………: 800 66.634307/s ws_msgs_sent……………….: 800 66.634307/s ws_session_duration…………: avg=189.21ms min=47.09ms med=145.6ms max=620.19ms p(90)=378.3ms p(95)=419.19ms ws_sessions………………..: 800 66.634307/s You can also see a set of new websocket-related metrics in the k6 output. As you can see the HTTP request p(90) has almost doubled (510ms vs 274ms). HTTP requests per second dropped to about 66 (from 83). You\u0026rsquo;ll find a lower overall VU threshold because the websockets mean more file descriptors. The main benefit however, is that you are now simulating a more realistic load on your LiveView app.\nWhere to from here #It\u0026rsquo;s possible with k6/ws to simulate navigation within the LiveView (by keeping the websocket open and sending redirect or patch messages). With this approach you should see more exact resource memory consumption (in particular any memory overhead) on your servers.\nIf your app uses LiveView, your load scripts may use k6/ws more than k6/http. However if k6/http provides you with a \u0026lsquo;good enough\u0026rsquo; load test, start there, as the API is simpler, and your load scripts will be easier to grok. Also check out some various test types that k6 has to offer, for example ramping stress tests.\n","date":"25 October 2022","permalink":"/posts/2022/10/25/how-to-test-your-elixir-phoenix-liveview-apps-with-k6./","section":"Posts","summary":"","title":"How to test your Elixir Phoenix LiveView apps with k6."},{"content":"","date":null,"permalink":"/tags/liveview/","section":"Tags","summary":"","title":"LiveView"},{"content":"","date":null,"permalink":"/categories/load-testing/","section":"Categories","summary":"","title":"Load-Testing"},{"content":"","date":null,"permalink":"/tags/phoenix/","section":"Tags","summary":"","title":"Phoenix"},{"content":"","date":null,"permalink":"/categories/algorithms/","section":"Categories","summary":"","title":"Algorithms"},{"content":"I recently came across a problem in Elixir where I needed to shift a list of items by a given offset aka an \u0026ldquo;Array Circular shift.\u0026rdquo;\nOther language solutions for this exist on StackOverflow and TheoryApp.\nThese appear to be implementations of Jon Bentley\u0026rsquo;s algorithm in Programming Pearls 2nd Edition, which solves the problem in O(n) time.\nI wrote an Elixir implementation using Enum.reverse_slice/3\ndefmodule ListShift do @moduledoc \u0026#34;\u0026#34;\u0026#34; Circle shift a list by a given number of positions in O(n) time. An implementation of the algorithm described in Jon Bentley\u0026#39;s \u0026#34;Programming Pearls 2nd Edition\u0026#34;. ## Examples iex\u0026gt; ListShift.left([1, 2, 3, 4], 1) [2, 3, 4, 1] iex\u0026gt; ListShift.left([1, 2, 3, 4], 2) [3, 4, 1, 2] iex\u0026gt; ListShift.left([1, 2, 3, 4], 3) [4, 1, 2, 3] iex\u0026gt; ListShift.left([1, 2, 3, 4], 6) [1, 2, 3, 4] iex\u0026gt; ListShift.left([1, 2, 3, 4], -1) [1, 2, 3, 4] \u0026#34;\u0026#34;\u0026#34; def left(list, n) when n \u0026lt; 0, do: list def left(list, n) do size = Enum.count(list) list |\u0026gt; Enum.reverse_slice(n, size) |\u0026gt; Enum.reverse_slice(0, n) |\u0026gt; Enum.reverse_slice(0, size) end end Tested with doctests as follows:\ndefmodule ListShiftTest do use ExUnit.Case doctest ListShift end ","date":"27 September 2020","permalink":"/posts/2020/09/27/circle-shift-an-array-in-elixir/","section":"Posts","summary":"","title":"Circle Shift an Array in Elixir"},{"content":"In my ongoing love affair with static code analysis tools, I wanted to find a good code linter for JavaScript, to use with Sublime. More specifically, a ReactJS project, with Mocha for tests, and of course using the awesome ES6 syntax (with Babel).\nWith a background in Ruby and Go, I\u0026rsquo;m used to some great tooling like Rubocop/BeautifyRuby/govet/gofmt/golint. There is a tight feedback loop when running a linter (automatically on saving a file). A team discussing+agreeing+following+evolving the same coding style on a project is a good thing, and fun process to be a part of.\nAlso, if you\u0026rsquo;re relatively new to a language, code linters can be a great source of learning to avoid common mistakes.\nIn terms of JavaScript, there are some decent JS linter tools out there, for example;\nJSLint JSCS JSHint ESLint In the context of my problem, Sublime+ES6+Babel, it came down to JSHint vs ESLint. JSHint was okay, and had decent support via SublimeLinter-jshint. However I was able to get up and running much faster with ESLint, with some help from Mr Redux himself, Dan A.\nMy current .eslintrc looks like this;\nMain style points include;\n2-space indentation dangling comma\u0026rsquo;s OK Standard ESLint React Plugin rules. ","date":"19 November 2015","permalink":"/posts/2015/11/19/eslint-config-for-react--redux-projects/","section":"Posts","summary":"","title":"ESLint config for React + Redux projects"},{"content":"","date":null,"permalink":"/tags/javascript/","section":"Tags","summary":"","title":"JavaScript"},{"content":"","date":null,"permalink":"/tags/reactjs/","section":"Tags","summary":"","title":"ReactJS"},{"content":"","date":null,"permalink":"/tags/redux/","section":"Tags","summary":"","title":"Redux"},{"content":"","date":null,"permalink":"/tags/sca/","section":"Tags","summary":"","title":"SCA"},{"content":"","date":null,"permalink":"/tags/static-analysis/","section":"Tags","summary":"","title":"Static-Analysis"},{"content":"","date":null,"permalink":"/tags/tooling/","section":"Tags","summary":"","title":"Tooling"},{"content":"","date":null,"permalink":"/categories/web-development/","section":"Categories","summary":"","title":"Web Development"},{"content":"","date":null,"permalink":"/tags/machine-learning/","section":"Tags","summary":"","title":"Machine-Learning"},{"content":"","date":null,"permalink":"/categories/ml/","section":"Categories","summary":"","title":"Ml"},{"content":"","date":null,"permalink":"/tags/ml/","section":"Tags","summary":"","title":"Ml"},{"content":"","date":null,"permalink":"/tags/neuroevolution/","section":"Tags","summary":"","title":"Neuroevolution"},{"content":"I was recently intrigued by Seth Bling\u0026rsquo;s MarI/O - a neural network slash genetic algorithm that teaches itself to play Super Mario World.\nSeth\u0026rsquo;s implementation (in Lua) is based on the concept of NeuroEvolution of Augmenting Topologies (or NEAT). NEAT is a type of genetic algorithm which generates efficient artificial neural networks (ANNs) from a very simple starting network. It does so rather quickly too (compared to other evolutionary algorithms).\nImage caption For another example of why this field is incredibly exciting, watch this amazing video of Google\u0026rsquo;s DeepMind learning and mastering space invaders. How good is that clutch shot at the end!\nSeth\u0026rsquo;s MarI/O can play both Super Mario World (SNES), and Super Mario Bros (NES). If you want to try it out yourself, read on.\nSetup (Windows 8.1) #To evolve your own ANN with MarI/O that can play Super Mario World, here\u0026rsquo;s how to do it;\nInstallation # Install BizHawk Prereqs\nDownload and unzip BizHawk\nGet a copy of Seth\u0026rsquo;s MarI/O (call it neatevolve.lua )\nPut neatevolve.lua in the root folder of your BizHawk folder. (In the same dir as the EmuHawk executable.)\nEmulator Setup # Set BizHawk video Mode to OpenGL (not GDI+)\nConfig \u0026gt; Display \u0026gt; Display Method \u0026gt; Open GL\nRestart BizHawk for settings to take effect. Double check it actually works.\nOptional: Set emulation speed to 200% - this makes the evolution go a lot faster!\nInitial State Setup #We need an initial/fresh game state that gets loaded for each genome. In other words, we need to save the ROM state at the start of the desired level we want MarI/O to learn.\nLoad the Super Mario World (USA).sfc ROM.\nStart a new game\nGo to the level you want MarI/O to learn. I chose Yoshi\u0026rsquo;s Island #1.\nInitial State Use the File -\u0026gt; Save Named State -\u0026gt; Save As \u0026ldquo;DP1.state\u0026rdquo; in the BizHawk root folder (i.e. in the same dir as neatevolve.lua). Now we have an initial state that MarI/O will load before each genome is evaluated.\nRunning MarI/O # Load neatevolve.lua. You can do this via Tools-\u0026gt;Lua Console. I prefer to drag and drop neatevolve.lua into the running emulator.\nMarI/O will load, creating a base set of about 300 very simple genomes. This is as per the NEAT methodology, which starts with a very simple ANNs (i.e. very few hidden nodes), and evolves from there.\nYou can see the ANN that MarI/O is currently evaluating by checking \u0026lsquo;Show Map\u0026rsquo; setting in the MarI/O \u0026lsquo;Fitness\u0026rsquo; window.\nCongratulations! If all goes well you\u0026rsquo;ll see Mario sitting there or jumping up and down, like an idiot, while it learns how to play the game. Don\u0026rsquo;t worry, it gets \u0026lsquo;smarter\u0026rsquo;.\nRestarting MarI/O #MarI/O saves the genomes of a given generation in a .pool file. The current generation being evaluated is saved in temp.pool. After each generation, a new .pool file will be saved, prefixed with the generation number.\nIf your computer melts, and you need to restart MarI/O;\nDelete temp.pool Copy the desired generation .pool file to DP1.state.pool In the MarI/O \u0026lsquo;Fitness\u0026rsquo; window, load the DP1.state.pool MarI/O should resume from the latest complete generation. Troubleshooting #Here are solutions to common errors myself an other people have ran into with MarI/O.\n\u0026lsquo;Buttonnames\u0026rsquo; error # LuaInterfae.LuaScriptException: [string \u0026quot;main\u0026quot;]:33: attempt to get length of global 'ButtonNames' (a nil value) The NEATevolve.lua script has a hardcoded (and relative) file reference to DP1.state. You need to make sure these files are in the same directory.\nCreate a Save State in BizHawk at the start of the level you want the algorithm to learn.\nyou\u0026rsquo;ll need to rename that file to DP1.state, and drop it in the same directory as the neatevolve.lua script. Putting both these files in the same directory as EmuHawk.exe is recommended\nSource discusson on reddit\n\u0026rsquo;neurons\u0026rsquo; error # LuaInterface.LuaScriptException: [string \u0026quot;main\u0026quot;]:337: attempt to index field 'neurons' (a nil value) A similar error - try the solution above, and failing that;\nAs above create a quicksave at the start of a level Renamed the QuickSave1.state found in /SNES/State/ to DP1.state and move it to the folder with the EmuHawk executable.\nPut the neatevolve.lua file in the same folder as EmuHawk.exe.\nNoticed while I was testing that it generated a temp.pool file that seemed to have all the variables in it. Renamed that file to DP1.state.pool\nSource discussion on reddit\n\u0026lsquo;Parameter name: source\u0026rsquo; error # \u0026quot;System.ArgumentNullException: Value cannot be null. Parameter name: source\u0026quot; Are you running MarI/O in a VM? Check out my notes on running MarI/O on OSX\nResources #Check out these discussions for more info on MarI/O\nSeth\u0026rsquo;s MarI/O frontpage post on /r/videos\n/r/machinelearning discussionc\n","date":"8 July 2015","permalink":"/posts/2015/07/08/neuroevolution-with-mario/","section":"Posts","summary":"","title":"NeuroEvolution with MarIO"}]